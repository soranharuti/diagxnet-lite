{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef9e098",
   "metadata": {},
   "source": [
    "# DiagXNet-Lite: Exploratory Data Analysis\n",
    "\n",
    "This notebook provides a comprehensive exploratory data analysis of the CheXpert dataset for chest X-ray diagnosis.\n",
    "\n",
    "## Overview\n",
    "- **Dataset**: CheXpert-small\n",
    "- **Task**: Multi-label classification of chest X-ray pathologies\n",
    "- **Labels**: 14 pathological observations\n",
    "- **Challenge**: Handling uncertain labels (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265538d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and load configuration\n",
    "import sys\n",
    "sys.path.append('../configs')\n",
    "from config import DATA_ROOT, CHEXPERT_LABELS\n",
    "\n",
    "# Data paths\n",
    "train_csv_path = DATA_ROOT / \"train\" / \"train.csv\"\n",
    "valid_csv_path = DATA_ROOT / \"valid\" / \"valid.csv\"\n",
    "\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "print(f\"Train CSV: {train_csv_path}\")\n",
    "print(f\"Valid CSV: {valid_csv_path}\")\n",
    "print(f\"Labels: {CHEXPERT_LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef40fd",
   "metadata": {},
   "source": [
    "## 1. Dataset Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "print(f\"Training dataset shape: {train_df.shape}\")\n",
    "print(f\"Number of samples: {len(train_df)}\")\n",
    "print(f\"Number of features: {train_df.shape[1]}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"Dataset Info:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(train_df.columns):\n",
    "    print(f\"{i+1:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a01286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Basic Statistics:\")\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef417fe",
   "metadata": {},
   "source": [
    "## 2. Patient Demographics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06364968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Age distribution\n",
    "axes[0,0].hist(train_df['Age'].dropna(), bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Age Distribution')\n",
    "axes[0,0].set_xlabel('Age')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "\n",
    "# Sex distribution\n",
    "sex_counts = train_df['Sex'].value_counts()\n",
    "axes[0,1].pie(sex_counts.values, labels=sex_counts.index, autopct='%1.1f%%')\n",
    "axes[0,1].set_title('Sex Distribution')\n",
    "\n",
    "# Frontal/Lateral distribution\n",
    "view_counts = train_df['Frontal/Lateral'].value_counts()\n",
    "axes[1,0].bar(view_counts.index, view_counts.values, color=['lightcoral', 'lightgreen'])\n",
    "axes[1,0].set_title('View Type Distribution')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "\n",
    "# AP/PA distribution\n",
    "ap_pa_counts = train_df['AP/PA'].value_counts()\n",
    "axes[1,1].bar(ap_pa_counts.index, ap_pa_counts.values, color=['gold', 'orange'])\n",
    "axes[1,1].set_title('AP/PA Distribution')\n",
    "axes[1,1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Age statistics:\")\n",
    "print(f\"  Mean: {train_df['Age'].mean():.1f} years\")\n",
    "print(f\"  Median: {train_df['Age'].median():.1f} years\")\n",
    "print(f\"  Range: {train_df['Age'].min():.0f} - {train_df['Age'].max():.0f} years\")\n",
    "print(f\"  Missing: {train_df['Age'].isna().sum()} ({train_df['Age'].isna().mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f3b5f",
   "metadata": {},
   "source": [
    "## 3. Label Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c7d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pathology labels (excluding metadata columns)\n",
    "pathology_columns = CHEXPERT_LABELS\n",
    "pathology_data = train_df[pathology_columns]\n",
    "\n",
    "print(f\"Pathology labels: {pathology_columns}\")\n",
    "print(f\"Pathology data shape: {pathology_data.shape}\")\n",
    "\n",
    "# Check unique values in each label column\n",
    "print(\"\\nUnique values in each pathology column:\")\n",
    "for col in pathology_columns:\n",
    "    unique_vals = sorted(pathology_data[col].dropna().unique())\n",
    "    print(f\"{col:25s}: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label distribution analysis\n",
    "label_stats = []\n",
    "\n",
    "for col in pathology_columns:\n",
    "    col_data = pathology_data[col]\n",
    "    total = len(col_data)\n",
    "    \n",
    "    positive = (col_data == 1.0).sum()\n",
    "    negative = (col_data == 0.0).sum()\n",
    "    uncertain = (col_data == -1.0).sum()\n",
    "    missing = col_data.isna().sum()\n",
    "    \n",
    "    label_stats.append({\n",
    "        'Label': col,\n",
    "        'Positive': positive,\n",
    "        'Negative': negative, \n",
    "        'Uncertain': uncertain,\n",
    "        'Missing': missing,\n",
    "        'Positive%': positive/total*100,\n",
    "        'Negative%': negative/total*100,\n",
    "        'Uncertain%': uncertain/total*100,\n",
    "        'Missing%': missing/total*100\n",
    "    })\n",
    "\n",
    "label_stats_df = pd.DataFrame(label_stats)\n",
    "print(\"Label Distribution Statistics:\")\n",
    "label_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf42bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Positive cases\n",
    "axes[0,0].barh(label_stats_df['Label'], label_stats_df['Positive%'])\n",
    "axes[0,0].set_title('Positive Cases Distribution (%)')\n",
    "axes[0,0].set_xlabel('Percentage')\n",
    "\n",
    "# Uncertain cases\n",
    "axes[0,1].barh(label_stats_df['Label'], label_stats_df['Uncertain%'], color='orange')\n",
    "axes[0,1].set_title('Uncertain Cases Distribution (%)')\n",
    "axes[0,1].set_xlabel('Percentage')\n",
    "\n",
    "# Missing cases\n",
    "axes[1,0].barh(label_stats_df['Label'], label_stats_df['Missing%'], color='red')\n",
    "axes[1,0].set_title('Missing Cases Distribution (%)')\n",
    "axes[1,0].set_xlabel('Percentage')\n",
    "\n",
    "# Combined stacked bar chart\n",
    "x = range(len(pathology_columns))\n",
    "width = 0.8\n",
    "\n",
    "axes[1,1].barh(x, label_stats_df['Positive%'], width, label='Positive', color='green', alpha=0.8)\n",
    "axes[1,1].barh(x, label_stats_df['Negative%'], width, left=label_stats_df['Positive%'], \n",
    "              label='Negative', color='blue', alpha=0.8)\n",
    "axes[1,1].barh(x, label_stats_df['Uncertain%'], width, \n",
    "              left=label_stats_df['Positive%']+label_stats_df['Negative%'], \n",
    "              label='Uncertain', color='orange', alpha=0.8)\n",
    "axes[1,1].barh(x, label_stats_df['Missing%'], width,\n",
    "              left=label_stats_df['Positive%']+label_stats_df['Negative%']+label_stats_df['Uncertain%'],\n",
    "              label='Missing', color='red', alpha=0.8)\n",
    "\n",
    "axes[1,1].set_yticks(x)\n",
    "axes[1,1].set_yticklabels(label_stats_df['Label'])\n",
    "axes[1,1].set_xlabel('Percentage')\n",
    "axes[1,1].set_title('Complete Label Distribution')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347b147",
   "metadata": {},
   "source": [
    "## 4. Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some images for analysis\n",
    "sample_paths = train_df['Path'].sample(10, random_state=42)\n",
    "\n",
    "# Analyze image properties\n",
    "image_info = []\n",
    "\n",
    "for path in sample_paths:\n",
    "    full_path = DATA_ROOT / path\n",
    "    if full_path.exists():\n",
    "        try:\n",
    "            img = Image.open(full_path)\n",
    "            image_info.append({\n",
    "                'Path': path,\n",
    "                'Width': img.width,\n",
    "                'Height': img.height,\n",
    "                'Mode': img.mode,\n",
    "                'Format': img.format,\n",
    "                'Size_MB': full_path.stat().st_size / (1024*1024)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Path does not exist: {full_path}\")\n",
    "\n",
    "image_info_df = pd.DataFrame(image_info)\n",
    "print(\"Sample Image Properties:\")\n",
    "image_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ea218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image statistics\n",
    "if not image_info_df.empty:\n",
    "    print(\"Image Statistics:\")\n",
    "    print(f\"Width range: {image_info_df['Width'].min()} - {image_info_df['Width'].max()}\")\n",
    "    print(f\"Height range: {image_info_df['Height'].min()} - {image_info_df['Height'].max()}\")\n",
    "    print(f\"Average size: {image_info_df['Size_MB'].mean():.2f} MB\")\n",
    "    print(f\"Modes: {image_info_df['Mode'].unique()}\")\n",
    "    print(f\"Formats: {image_info_df['Format'].unique()}\")\n",
    "    \n",
    "    # Plot image size distribution\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].hist(image_info_df['Width'], bins=10, alpha=0.7)\n",
    "    axes[0].set_title('Image Width Distribution')\n",
    "    axes[0].set_xlabel('Width (pixels)')\n",
    "    \n",
    "    axes[1].hist(image_info_df['Height'], bins=10, alpha=0.7)\n",
    "    axes[1].set_title('Image Height Distribution')\n",
    "    axes[1].set_xlabel('Height (pixels)')\n",
    "    \n",
    "    axes[2].hist(image_info_df['Size_MB'], bins=10, alpha=0.7)\n",
    "    axes[2].set_title('File Size Distribution')\n",
    "    axes[2].set_xlabel('Size (MB)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971ee3d",
   "metadata": {},
   "source": [
    "## 5. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f081627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with their labels\n",
    "def plot_sample_images(df, n_samples=6):\n",
    "    \"\"\"Plot sample images with their pathology labels\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    sample_indices = np.random.choice(len(df), n_samples, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        row = df.iloc[idx]\n",
    "        img_path = DATA_ROOT / row['Path']\n",
    "        \n",
    "        if img_path.exists():\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "                axes[i].imshow(img, cmap='gray')\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "                # Create title with pathology labels\n",
    "                positive_labels = []\n",
    "                for label in pathology_columns:\n",
    "                    if row[label] == 1.0:\n",
    "                        positive_labels.append(label.replace(' ', '\\n'))\n",
    "                \n",
    "                title = f\"Age: {row['Age']}, Sex: {row['Sex']}\\n\"\n",
    "                if positive_labels:\n",
    "                    title += \"Findings: \" + \", \".join(positive_labels[:3])  # Show first 3\n",
    "                    if len(positive_labels) > 3:\n",
    "                        title += f\" (+{len(positive_labels)-3} more)\"\n",
    "                else:\n",
    "                    title += \"No positive findings\"\n",
    "                \n",
    "                axes[i].set_title(title, fontsize=8)\n",
    "            except Exception as e:\n",
    "                axes[i].text(0.5, 0.5, f'Error loading\\n{str(e)}', \n",
    "                           ha='center', va='center', transform=axes[i].transAxes)\n",
    "                axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, 'Image not found', \n",
    "                       ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot sample images\n",
    "plot_sample_images(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43992762",
   "metadata": {},
   "source": [
    "## 6. Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the uncertainty patterns\n",
    "print(\"Uncertainty Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Total uncertain cases per pathology\n",
    "uncertain_counts = (pathology_data == -1.0).sum().sort_values(ascending=False)\n",
    "print(\"\\nPathologies with most uncertain labels:\")\n",
    "for label, count in uncertain_counts.head(10).items():\n",
    "    percentage = count / len(pathology_data) * 100\n",
    "    print(f\"{label:25s}: {count:6d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# Samples with multiple uncertain labels\n",
    "uncertain_per_sample = (pathology_data == -1.0).sum(axis=1)\n",
    "print(f\"\\nSamples with uncertain labels:\")\n",
    "print(f\"No uncertain labels: {(uncertain_per_sample == 0).sum():6d} ({(uncertain_per_sample == 0).mean()*100:5.1f}%)\")\n",
    "print(f\"1+ uncertain labels: {(uncertain_per_sample > 0).sum():6d} ({(uncertain_per_sample > 0).mean()*100:5.1f}%)\")\n",
    "print(f\"5+ uncertain labels: {(uncertain_per_sample >= 5).sum():6d} ({(uncertain_per_sample >= 5).mean()*100:5.1f}%)\")\n",
    "print(f\"Max uncertain per sample: {uncertain_per_sample.max()}\")\n",
    "\n",
    "# Plot uncertainty distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "uncertain_counts.plot(kind='barh')\n",
    "plt.title('Uncertain Labels by Pathology')\n",
    "plt.xlabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(uncertain_per_sample, bins=range(15), alpha=0.7)\n",
    "plt.title('Distribution of Uncertain Labels per Sample')\n",
    "plt.xlabel('Number of Uncertain Labels')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd153a",
   "metadata": {},
   "source": [
    "## 7. Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class imbalance ratios\n",
    "imbalance_stats = []\n",
    "\n",
    "for col in pathology_columns:\n",
    "    col_data = pathology_data[col]\n",
    "    \n",
    "    # Consider only non-missing, non-uncertain labels for imbalance calculation\n",
    "    valid_data = col_data[(col_data == 0.0) | (col_data == 1.0)]\n",
    "    \n",
    "    if len(valid_data) > 0:\n",
    "        positive = (valid_data == 1.0).sum()\n",
    "        negative = (valid_data == 0.0).sum()\n",
    "        \n",
    "        pos_ratio = positive / len(valid_data)\n",
    "        imbalance_ratio = negative / positive if positive > 0 else float('inf')\n",
    "        \n",
    "        imbalance_stats.append({\n",
    "            'Label': col,\n",
    "            'Positive': positive,\n",
    "            'Negative': negative,\n",
    "            'Total_Valid': len(valid_data),\n",
    "            'Positive_Ratio': pos_ratio,\n",
    "            'Imbalance_Ratio': imbalance_ratio\n",
    "        })\n",
    "\n",
    "imbalance_df = pd.DataFrame(imbalance_stats)\n",
    "imbalance_df = imbalance_df.sort_values('Imbalance_Ratio', ascending=False)\n",
    "\n",
    "print(\"Class Imbalance Analysis:\")\n",
    "print(\"(Imbalance Ratio = Negative / Positive)\")\n",
    "print(\"\\nMost imbalanced classes:\")\n",
    "imbalance_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class imbalance\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Positive ratio\n",
    "axes[0].barh(imbalance_df['Label'], imbalance_df['Positive_Ratio'])\n",
    "axes[0].set_title('Positive Class Ratio by Pathology')\n",
    "axes[0].set_xlabel('Positive Ratio')\n",
    "axes[0].axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Balanced (0.5)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Imbalance ratio (log scale)\n",
    "finite_ratios = imbalance_df[imbalance_df['Imbalance_Ratio'] != float('inf')]\n",
    "axes[1].barh(finite_ratios['Label'], np.log10(finite_ratios['Imbalance_Ratio']))\n",
    "axes[1].set_title('Class Imbalance Ratio (log10 scale)')\n",
    "axes[1].set_xlabel('log10(Negative/Positive)')\n",
    "axes[1].axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Balanced (log10(1)=0)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nImbalance Summary:\")\n",
    "print(f\"Most balanced class: {imbalance_df.loc[imbalance_df['Imbalance_Ratio'].idxmin(), 'Label']} (ratio: {imbalance_df['Imbalance_Ratio'].min():.2f})\")\n",
    "print(f\"Most imbalanced class: {imbalance_df.loc[imbalance_df['Imbalance_Ratio'].idxmax(), 'Label']} (ratio: {imbalance_df['Imbalance_Ratio'].max():.2f})\")\n",
    "print(f\"Average positive ratio: {imbalance_df['Positive_Ratio'].mean():.3f}\")\n",
    "print(f\"Median positive ratio: {imbalance_df['Positive_Ratio'].median():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21364d9e",
   "metadata": {},
   "source": [
    "## 8. Co-occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pathology co-occurrence patterns\n",
    "# Convert uncertain labels to 0 for this analysis\n",
    "binary_labels = pathology_data.copy()\n",
    "binary_labels[binary_labels == -1.0] = 0.0  # Treat uncertain as negative\n",
    "binary_labels = binary_labels.fillna(0.0)    # Treat missing as negative\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = binary_labels.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # Mask upper triangle\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Pathology Co-occurrence Correlation Matrix')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find strongest correlations\n",
    "correlation_pairs = []\n",
    "for i in range(len(pathology_columns)):\n",
    "    for j in range(i+1, len(pathology_columns)):\n",
    "        corr = correlation_matrix.iloc[i, j]\n",
    "        correlation_pairs.append({\n",
    "            'Pathology_1': pathology_columns[i],\n",
    "            'Pathology_2': pathology_columns[j],\n",
    "            'Correlation': corr\n",
    "        })\n",
    "\n",
    "correlation_pairs_df = pd.DataFrame(correlation_pairs)\n",
    "correlation_pairs_df = correlation_pairs_df.sort_values('Correlation', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nStrongest pathology correlations:\")\n",
    "print(correlation_pairs_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b60922",
   "metadata": {},
   "source": [
    "## 9. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf314ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and recommendations\n",
    "print(\"DiagXNet-Lite: Dataset Analysis Summary\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Overview:\")\n",
    "print(f\"   â€¢ Total samples: {len(train_df):,}\")\n",
    "print(f\"   â€¢ Pathology labels: {len(pathology_columns)}\")\n",
    "print(f\"   â€¢ Patient age range: {train_df['Age'].min():.0f}-{train_df['Age'].max():.0f} years\")\n",
    "print(f\"   â€¢ View types: {train_df['Frontal/Lateral'].value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nðŸ·ï¸ Label Characteristics:\")\n",
    "total_uncertain = (pathology_data == -1.0).sum().sum()\n",
    "total_missing = pathology_data.isna().sum().sum()\n",
    "total_positive = (pathology_data == 1.0).sum().sum()\n",
    "print(f\"   â€¢ Total uncertain labels: {total_uncertain:,} ({total_uncertain/(len(train_df)*len(pathology_columns))*100:.1f}%)\")\n",
    "print(f\"   â€¢ Total missing labels: {total_missing:,} ({total_missing/(len(train_df)*len(pathology_columns))*100:.1f}%)\")\n",
    "print(f\"   â€¢ Total positive labels: {total_positive:,} ({total_positive/(len(train_df)*len(pathology_columns))*100:.1f}%)\")\n",
    "print(f\"   â€¢ Most common pathology: {label_stats_df.loc[label_stats_df['Positive'].idxmax(), 'Label']}\")\n",
    "print(f\"   â€¢ Least common pathology: {label_stats_df.loc[label_stats_df['Positive'].idxmin(), 'Label']}\")\n",
    "\n",
    "print(f\"\\nâš–ï¸ Class Imbalance:\")\n",
    "balanced_threshold = 0.1  # Consider classes with 10-90% positive ratio as relatively balanced\n",
    "balanced_classes = imbalance_df[(imbalance_df['Positive_Ratio'] >= balanced_threshold) & \n",
    "                               (imbalance_df['Positive_Ratio'] <= 1-balanced_threshold)]\n",
    "print(f\"   â€¢ Relatively balanced classes: {len(balanced_classes)}/{len(imbalance_df)}\")\n",
    "print(f\"   â€¢ Most imbalanced: {imbalance_df.iloc[0]['Label']} (ratio: {imbalance_df.iloc[0]['Imbalance_Ratio']:.1f}:1)\")\n",
    "print(f\"   â€¢ Average positive ratio: {imbalance_df['Positive_Ratio'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ”— Co-occurrence Patterns:\")\n",
    "strong_correlations = correlation_pairs_df[abs(correlation_pairs_df['Correlation']) > 0.3]\n",
    "print(f\"   â€¢ Strong correlations (>0.3): {len(strong_correlations)}\")\n",
    "if len(strong_correlations) > 0:\n",
    "    top_corr = correlation_pairs_df.iloc[0]\n",
    "    print(f\"   â€¢ Strongest correlation: {top_corr['Pathology_1']} â†” {top_corr['Pathology_2']} ({top_corr['Correlation']:.3f})\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ Recommendations for Model Development:\")\n",
    "print(f\"   1. Handle uncertain labels carefully - consider U-Ignore or U-Zeros strategies\")\n",
    "print(f\"   2. Address class imbalance with weighted loss functions or sampling strategies\")\n",
    "print(f\"   3. Consider multi-label classification metrics (AUC-ROC, AUC-PR per class)\")\n",
    "print(f\"   4. Leverage pathology correlations for multi-task learning\")\n",
    "print(f\"   5. Implement data augmentation to increase dataset diversity\")\n",
    "print(f\"   6. Use stratified sampling to maintain label distribution in train/val splits\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Next Steps:\")\n",
    "print(f\"   1. Implement data preprocessing pipeline\")\n",
    "print(f\"   2. Create baseline model evaluation\")\n",
    "print(f\"   3. Develop custom architectures for multi-label classification\")\n",
    "print(f\"   4. Implement uncertainty-aware training strategies\")\n",
    "print(f\"   5. Add interpretability analysis (GradCAM, attention maps)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
