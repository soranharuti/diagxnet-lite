# DenseNet-121 + Vision Transformer Ensemble Analysis Report

**Date:** October 13, 2025  
**Evaluation Dataset:** CheXpert Validation Set (234 samples)

---

## Executive Summary

The DenseNet-121 + Vision Transformer ensemble is **significantly underperforming** compared to both individual base models. This report analyzes the root causes and proposes solutions.

### Performance Comparison

| Model | Mean AUROC | Mean AUPRC | Rank |
|-------|------------|------------|------|
| **DenseNet-121** | **0.7681** | **0.4728** | ü•á 1st |
| **Vision Transformer** | 0.7135 | 0.4538 | ü•à 2nd |
| **Ensemble** | 0.6802 | 0.4202 | ü•â 3rd (Worst!) |

**Key Finding:** The ensemble performs **8.8% worse in AUROC** and **5.3% worse in AUPRC** compared to the best individual model (DenseNet-121).

---

## Root Cause Analysis

### 1. ‚ö†Ô∏è **Insufficient Training**

**Training Configuration:**
- Meta-learner epochs: **Only 5 epochs**
- Learning rate: 1e-5 (very conservative)
- Base models: Frozen during meta-learner training
- Validation loss progression:
  - Epoch 1: 1.1115
  - Epoch 2: 1.0808
  - Epoch 3: 1.0575
  - Epoch 4: 1.0418
  - Epoch 5: 1.0299

**Analysis:**
- Loss is still **consistently decreasing** after epoch 5
- No plateau or convergence indicators
- Training was stopped prematurely
- Meta-learner didn't have enough iterations to learn optimal combination weights

**Evidence:** The validation loss decreased by **7.3%** from epoch 1 to 5, with a steady decline suggesting more training could improve performance.

### 2. üß† **Meta-Learner Architecture Limitations**

**Current Architecture:**
```
Input: [28 features] (2 models √ó 14 classes)
    ‚Üì
Linear(28 ‚Üí 64) + ReLU + Dropout(0.2)
    ‚Üì
Linear(64 ‚Üí 32) + ReLU + Dropout(0.2)
    ‚Üì
Linear(32 ‚Üí 14)
```

**Potential Issues:**
- **Small hidden dimension (64)**: May not capture complex interactions
- **Simple 3-layer network**: Limited representation capacity
- **No attention mechanism**: Cannot learn per-class importance weighting
- **No residual connections**: May suffer from vanishing gradients

### 3. üìä **Class Imbalance Issues**

**Severely Imbalanced Classes:**
- **Lung Lesion**: 1 positive / 233 negative (0.4% positive rate)
- **Pleural Other**: 1 positive / 233 negative (0.4% positive rate)
- **Pneumonia**: 8 positive / 226 negative (3.4% positive rate)
- **Pneumothorax**: 8 positive / 226 negative (3.4% positive rate)
- **Fracture**: 0 positives (cannot be evaluated)

**Ensemble Performance on Rare Classes:**
- Lung Lesion: AUROC = 0.1288 (random guessing is 0.5!)
- Pleural Other: AUROC = 0.6309 (much worse than base models)

**Analysis:** The meta-learner struggles with rare classes, possibly due to insufficient training examples or class weights not being properly utilized.

### 4. üîß **Training Strategy Issues**

**Current Approach:**
1. Train DenseNet-121 (10 epochs)
2. Train Vision Transformer (10 epochs)
3. Freeze both models
4. Train meta-learner (5 epochs)

**Limitations:**
- **No fine-tuning phase**: Base models never adapt to work together
- **Frozen features**: Cannot adjust feature representations for ensemble
- **Separate training**: Base models trained independently, not collaboratively

---

## Per-Class Performance Analysis

### Classes Where Ensemble Improves ‚úÖ

| Pathology | DenseNet AUROC | ViT AUROC | Ensemble AUROC | Improvement |
|-----------|----------------|-----------|----------------|-------------|
| Enlarged Cardiomediastinum | 0.5376 | 0.4247 | **0.5811** | +0.0435 |
| Pleural Effusion | 0.8669 | 0.8926 | **0.8917** | +0.0248 |

**Only 2 out of 13 evaluable classes show improvement!**

### Classes Where Ensemble Degrades ‚ö†Ô∏è

| Pathology | Best Base | Ensemble | Degradation |
|-----------|-----------|----------|-------------|
| Lung Opacity | 0.8372 | 0.7375 | **-0.0997** |
| Support Devices | 0.8045 | 0.6217 | **-0.1828** |
| Edema | 0.9055 | 0.7922 | **-0.1133** |
| Atelectasis | 0.7902 | 0.7242 | **-0.0660** |
| Pneumothorax | 0.8114 | 0.6643 | **-0.1471** |

---

## Recommendations

### üî• **Immediate Actions (High Priority)**

#### 1. **Increase Meta-Learner Training**
```bash
# Re-train with more epochs
python scripts/train_meta_learner_only.py --epochs-meta 20 --lr-meta 1e-4
```
- Increase from 5 to **20-30 epochs**
- Monitor validation loss for plateau
- Implement early stopping with patience=5

#### 2. **Larger Meta-Learner Architecture**
```python
# Increase hidden dimension
ensemble = create_ensemble(
    model1=densenet,
    model2=vit,
    hidden_dim=256,  # Increase from 64 to 256
    num_classes=14
)
```

#### 3. **Add Learning Rate Scheduler**
```python
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=3
)
```

### üéØ **Medium-Term Improvements**

#### 4. **Implement Attention-Based Meta-Learner**
- Add self-attention to learn importance of each base model per class
- Use cross-attention between base model predictions
- Learn per-pathology weighting dynamically

#### 5. **Two-Stage Fine-Tuning**
```python
# Stage 1: Train meta-learner (10 epochs, base frozen)
# Stage 2: Fine-tune entire ensemble (5 epochs, all trainable)
```

#### 6. **Better Class Balancing**
- Use focal loss instead of BCE
- Implement SMOTE or oversampling for rare classes
- Adjust per-class weights more aggressively

### üöÄ **Advanced Strategies**

#### 7. **Ensemble Distillation**
- Train a single model to mimic the ensemble
- May achieve better performance with simpler architecture

#### 8. **Feature-Level Fusion**
Instead of prediction-level fusion, extract and combine intermediate features:
```python
# Extract features before final layer
features1 = densenet.features(x)
features2 = vit.encoder(x)
combined = meta_learner([features1, features2])
```

#### 9. **Dynamic Weighting**
Learn different ensemble weights for different pathologies:
```python
class AdaptiveMetaLearner(nn.Module):
    def __init__(self):
        self.per_class_attention = nn.MultiheadAttention(...)
```

---

## Training Configuration Recommendations

### Optimal Hyperparameters

```yaml
meta_learner:
  epochs: 20-30
  learning_rate: 1e-4  # Increase from 1e-5
  hidden_dim: 256      # Increase from 64
  dropout: 0.3         # Increase from 0.2
  architecture: attention_based
  
optimizer:
  type: AdamW
  weight_decay: 1e-4
  betas: [0.9, 0.999]

scheduler:
  type: ReduceLROnPlateau
  patience: 5
  factor: 0.5
  
loss:
  type: FocalLoss      # Better for imbalanced data
  alpha: class_weights
  gamma: 2.0

early_stopping:
  patience: 10
  min_delta: 0.001
```

---

## Next Steps

1. ‚úÖ **Fixed evaluation script bug** (ViT string matching)
2. ‚úÖ **Added architectural parameter passing** (hidden_dim support)
3. ‚úÖ **Analyzed training history and identified issues**
4. üîÑ **Re-train meta-learner with recommended configurations**
5. üîÑ **Implement attention-based meta-learner**
6. üîÑ **Add two-stage fine-tuning pipeline**
7. üîÑ **Compare with simple weighted average baseline**

---

## Conclusion

The current ensemble underperforms due to:
1. **Insufficient training** (only 5 epochs)
2. **Small meta-learner capacity** (hidden_dim=64)
3. **No fine-tuning phase**
4. **Poor handling of class imbalance**

**Expected improvement with recommended changes:** +10-15% AUROC improvement possible, potentially surpassing individual model performance.

**Quick Win:** Simply training for 20 epochs with hidden_dim=256 could immediately improve performance without architectural changes.

---

## Files Generated

- ‚úÖ `evaluation_report.txt` - Numerical results
- ‚úÖ `auroc_comparison.png` - AUROC visualization
- ‚úÖ `auprc_comparison.png` - AUPRC visualization
- ‚úÖ `improvement_heatmap.png` - Per-class improvement analysis
- ‚úÖ `ANALYSIS_REPORT.md` - This comprehensive analysis

**Evaluation Command:**
```bash
PYTHONPATH=/Users/soranharuti/Desktop/diagxnet-lite:$PYTHONPATH \
  python scripts/evaluate_densenet_vit_ensemble.py
```
